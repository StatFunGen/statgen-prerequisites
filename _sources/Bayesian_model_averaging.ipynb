{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b954b098",
   "metadata": {},
   "source": [
    "# Intuitional Description\n",
    "\n",
    "Bayesian Model Averaging improves predictions by combining multiple models weighted by their posterior probabilities, acknowledging uncertainty in model selection rather than relying on a single \"best\" model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52667222",
   "metadata": {},
   "source": [
    "# Graphical Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b45120c",
   "metadata": {},
   "source": [
    "![figure](./cartoons/Bayesian_model_averaging.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b142e6",
   "metadata": {},
   "source": [
    "# Key Formula\n",
    "\n",
    "Letâ€™s assume we have a set of models $M_1, M_2, \\dots, M_K$ and we want to predict a value for a new observation $y^*$ based on the models. For each model $M_k$, we calculate a prediction, denoted as $\\hat{y}^*_k$. \n",
    "\n",
    "The **model-averaged prediction** is typically given by the weighted sum of the predictions from each model:\n",
    "\n",
    "$$\n",
    "\\hat{y}^*_{\\text{avg}} = \\sum_{k=1}^{K} w_k \\hat{y}^*_k\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $w_k$ is the weight associated with model $M_k$, which reflects how likely or good the model is at describing the data.\n",
    "- $\\hat{y}^*_k$ is the prediction made by model $M_k$ for the new data point.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92408f88",
   "metadata": {},
   "source": [
    "# Technical Details\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea5b17b",
   "metadata": {},
   "source": [
    "## Weights in Model Averaging\n",
    "\n",
    "The weights $w_k$ can be assigned based on various criteria:\n",
    "1. **Bayesian Model Averaging (BMA)**: In the Bayesian framework, the weights correspond to the posterior model probabilities, i.e., the probability of each model given the data:\n",
    "\n",
    "   $$ \n",
    "   w_k = P(M_k | D) \n",
    "   $$\n",
    "\n",
    "   Where $P(M_k | D)$ is the posterior probability of model $M_k$ given the observed data $D$.\n",
    "\n",
    "2. **[Do we want to include AIC and BIC???]**\n",
    "\n",
    "**Akaike Information Criterion (AIC) or Bayesian Information Criterion (BIC)**: In a frequentist context, the weights are often computed based on the relative likelihood of each model, using information criteria like AIC or BIC. The models with lower AIC/BIC values are considered to be more likely and receive higher weights.\n",
    "\n",
    "   $$ \n",
    "   w_k = \\frac{e^{-\\frac{1}{2} \\Delta \\text{AIC}_k}}{\\sum_{j=1}^K e^{-\\frac{1}{2} \\Delta \\text{AIC}_j}} \n",
    "   $$\n",
    "\n",
    "   Where $\\Delta \\text{AIC}_k = \\text{AIC}_k - \\min(\\text{AIC})$, and $\\text{AIC}_k$ is the AIC of model $k$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03ac6af-c3b1-47fd-8592-cd9246471a4b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Why Model Averaging Works\n",
    "\n",
    "\n",
    "\n",
    "BMA accounts for the uncertainty involved in selecting the model, **preserving the uncertainty about models**.\n",
    "\n",
    "1. **Reduced Risk of Overfitting**: By averaging over multiple models, we avoid overfitting to any one model. Even if one model fits the training data well but fails to generalize, other models can provide complementary information, reducing the overall risk of overfitting.\n",
    "  \n",
    "2. **Improved Accuracy**: If models make different types of errors, combining their predictions can reduce the variance and bias, leading to more accurate predictions.\n",
    "\n",
    "3. **Incorporating Model Uncertainty**: In cases where model uncertainty is high, model averaging incorporates this uncertainty by using multiple models and averaging their predictions, rather than relying on a single model.\n",
    "\n",
    "\n",
    "\n",
    "- **Advantages of BMA**\n",
    "    - Accounts for model uncertainty, leading to more robust inference.\n",
    "    - Prevents overconfidence in a single model when multiple models have similar posterior probabilities.\n",
    "    - Helps mitigate overfitting, especially with limited data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a200e1c3-4870-4370-8741-eda6809eb029",
   "metadata": {},
   "source": [
    "# Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65bf3cb-c17e-41a5-a0c2-72871b4b2361",
   "metadata": {},
   "source": [
    "We will introduce the concept of Bayesian Model Averaging (BMA) by considering a situation with a single SNP and two traits: height and weight. We define four models, where the SNP may or may not affect height and/or weight:\n",
    "\n",
    "\n",
    "Here we are trying to average the estimated effect sizes of the SNP on both height and weight across multiple possible models where the SNP may:\n",
    "- Have no effect on either trait (`Model 1`).\n",
    "- Affect height only (`Model 2`).\n",
    "- Affect weight only (`Model 3`).\n",
    "- Affect both height and weight (`Model 4`), capturing pleiotropy.\n",
    "\n",
    "\n",
    "Specifically, it's calculating:\n",
    "\n",
    "- A weighted average of the SNP's effect on height across four different models (no effect, height only, weight only, both traits)\n",
    "- A weighted average of the SNP's effect on weight across these same four models\n",
    "\n",
    "The weights used for this averaging are the posterior probabilities of each model - how likely each model is given the observed data. This means that models with higher posterior probabilities contribute more to the final averaged estimate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d2238a",
   "metadata": {},
   "source": [
    "We'll first randomly assign priors to these models. For simplicity, we assume equal priors for all models in the beginning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56532477",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "rm(list=ls())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57f110c1",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Set up model priors (randomly assign)\n",
    "model_priors <- c(0.25, 0.25, 0.25, 0.25) # Equal priors for simplicity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70cf9fb0",
   "metadata": {},
   "source": [
    "## Observe the data\n",
    "\n",
    "Assume we have summary statistics for the SNP with respect to both height and weight. We can simulate some data for the effect sizes (betas) and standard errors (SE).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93a44cca",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Simulated summary statistics (effect sizes and standard errors)\n",
    "observed_beta_height <- 0.2  # Observed effect size for height\n",
    "observed_se_height <- 0.05   # Standard error for height\n",
    "observed_beta_weight <- 0.1  # Observed effect size for weight\n",
    "observed_se_weight <- 0.05   # Standard error for weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89efe89",
   "metadata": {},
   "source": [
    "## Calculate Likelihoods\n",
    "\n",
    "Now we calculate the likelihood of observing the data under each model. In the context of summary statistics, the likelihood for a model is typically modeled as a normal distribution where the mean is the effect size and the variance is the standard error.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3ff4863",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Likelihood function based on normal distribution\n",
    "likelihood <- function(observed_beta, observed_se, model_beta) {\n",
    "  # Likelihood is the probability of observing observed_beta given model_beta and observed_se\n",
    "  # We use the normal density function (dnorm) to calculate this\n",
    "  return(dnorm(observed_beta, mean=model_beta, sd=observed_se))\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f006ef1",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Define likelihood for each model\n",
    "likelihoods <- c(\n",
    "  # Model 1: No effect (beta = 0 for both height and weight)\n",
    "  likelihood(observed_beta_height, observed_se_height, 0) * likelihood(observed_beta_weight, observed_se_weight, 0),  # SNP has no effect\n",
    "\n",
    "  # Model 2: SNP affects height (beta for height = observed, beta for weight = 0)\n",
    "  likelihood(observed_beta_height, observed_se_height, observed_beta_height) * likelihood(observed_beta_weight, observed_se_weight, 0),  # SNP affects height only\n",
    "\n",
    "  # Model 3: SNP affects weight (beta for weight = observed, beta for height = 0)\n",
    "  likelihood(observed_beta_height, observed_se_height, 0) * likelihood(observed_beta_weight, observed_se_weight, observed_beta_weight),  # SNP affects weight only\n",
    "\n",
    "  # Model 4: SNP affects both height and weight (pleiotropy)\n",
    "  likelihood(observed_beta_height, observed_se_height, observed_beta_height) * likelihood(observed_beta_weight, observed_se_weight, observed_beta_weight)  # SNP affects both traits\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0c43d9",
   "metadata": {},
   "source": [
    "## Calculate Bayes Factors and Posterior Probabilities\n",
    "\n",
    "The Bayes factor for each model is the ratio of the likelihood under that model to the likelihood under a null model (Model 1). We calculate the posterior probabilities for each model using Bayes' theorem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8a81288",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate Bayes factors (relative likelihood to Model 1)\n",
    "bayes_factors <- likelihoods / likelihoods[1]\n",
    "\n",
    "# Posterior probabilities (using priors and likelihoods)\n",
    "posterior_probabilities <- (likelihoods * model_priors) / sum(likelihoods * model_priors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "614bb42f",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>3.99747154521025e-05</li><li>0.119162947306665</li><li>0.000295375415014376</li><li>0.880501702562868</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 3.99747154521025e-05\n",
       "\\item 0.119162947306665\n",
       "\\item 0.000295375415014376\n",
       "\\item 0.880501702562868\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 3.99747154521025e-05\n",
       "2. 0.119162947306665\n",
       "3. 0.000295375415014376\n",
       "4. 0.880501702562868\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 3.997472e-05 1.191629e-01 2.953754e-04 8.805017e-01"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "posterior_probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9205667",
   "metadata": {},
   "source": [
    "## Bayesian Model Averaging (BMA)\n",
    "We perform Bayesian model averaging by computing a weighted average of the effects across all models, where the weights are the posterior probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "015f8776",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bayesian Model Averaging (BMA) Estimates:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BMA Estimate for Height Effect:  0.1999329 \n",
      "BMA Estimate for Weight Effect:  0.08807971 \n"
     ]
    }
   ],
   "source": [
    "# Now, we can calculate the Bayesian Model Averaging (BMA) estimate\n",
    "# For each model, we calculate the weighted average of the effect sizes (betas)\n",
    "\n",
    "# Effect sizes (betas) for each model:\n",
    "betas_height <- c(0, observed_beta_height, 0, observed_beta_height)  # Height betas for each model\n",
    "betas_weight <- c(0, 0, observed_beta_weight, observed_beta_weight)  # Weight betas for each model\n",
    "\n",
    "# Compute BMA estimates for height and weight\n",
    "bma_height <- sum(posterior_probabilities * betas_height)\n",
    "bma_weight <- sum(posterior_probabilities * betas_weight)\n",
    "\n",
    "# Print the BMA estimates\n",
    "cat(\"Bayesian Model Averaging (BMA) Estimates:\\n\")\n",
    "cat(\"BMA Estimate for Height Effect: \", bma_height, \"\\n\")\n",
    "cat(\"BMA Estimate for Weight Effect: \", bma_weight, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6afad60",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.3"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
